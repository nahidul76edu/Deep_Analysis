{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_retinanet for custom object detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "id": "2PlZ8aDqEVPW",
        "outputId": "dc37f429-ebb6-418f-ab1d-bcfe39788fba"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "function ClickConnect(){\n",
              "console.log(\"Working\");\n",
              "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
              "}setInterval(ClickConnect,60000)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Ensure colab doesn't disconnect\n",
        "%%javascript\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}setInterval(ClickConnect,60000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uqq pytorch-lightning==1.0.0 omegaconf\n",
        "!pip install -Uqq git+https://github.com/albumentations-team/albumentations\n",
        "!pip uninstall torchtext\n",
        "!git clone https://github.com/benihime91/pytorch_retinanet.git"
      ],
      "metadata": {
        "id": "vA-tuNH9EmEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision==0.7.0"
      ],
      "metadata": {
        "id": "_oh-0N8hYaUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Update sys path to include the pytorch RetinaNet modules\n",
        "import warnings\n",
        "import os\n",
        "import sys\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "sys.path.append(\"/content/pytorch_retinanet/\")\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "RkZoCI25EwMO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set up paths \n",
        "\n",
        "#Path to where the Images are stored\n",
        "TRAIN_IMAGE_PATH = \"/content/drive/MyDrive/#ratinanet/Images/train_img/\"\n",
        "VALID_IMAGE_PATH = \"/content/drive/MyDrive/#ratinanet/Images/val_img/\"\n",
        "TEST_IMAGE_PATH  = \"/content/drive/MyDrive/#ratinanet/Images/test_img\"\n",
        "#Path to where annotations are stored\n",
        "TRAIN_ANNOT_PATH = \"/content/drive/MyDrive/#ratinanet/anotations/train_ant/\"\n",
        "VALID_ANNOT_PATH = \"/content/drive/MyDrive/#ratinanet/anotations/val_ant/\"\n",
        "TEST_ANNOT_PATH  = \"/content/drive/MyDrive/#ratinanet/anotations/test_ant/\""
      ],
      "metadata": {
        "id": "fNuXE-51Ff_1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python-headless==4.5.2.52"
      ],
      "metadata": {
        "id": "Jdtz9EvoF5Ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "from utils.pascal import convert_annotations_to_df\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "np.random.seed(123)"
      ],
      "metadata": {
        "id": "OkzdCR_6FsO9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert xml files to pandas DataFrames\n",
        "train_df = convert_annotations_to_df(TRAIN_ANNOT_PATH, TRAIN_IMAGE_PATH, image_set=\"train\")\n",
        "valid_df = convert_annotations_to_df(VALID_ANNOT_PATH, VALID_IMAGE_PATH, image_set=\"test\")\n",
        "test_df  = convert_annotations_to_df(TEST_ANNOT_PATH, TEST_IMAGE_PATH, image_set=\"test\")\n",
        "\n",
        "\n",
        "def remove_invalid_annots(df):\n",
        "    \"\"\"\n",
        "    Removes annotations where xmax, ymax < xmin,ymin\n",
        "    from the given dataframe\n",
        "    \"\"\"\n",
        "    df = df[df.xmax > df.xmin]\n",
        "    df = df[df.ymax > df.ymin]\n",
        "    df.reset_index(inplace=True, drop=True)\n",
        "    return df\n",
        "\n",
        "# removing annotations that are not valid annotations\n",
        "train_df = remove_invalid_annots(train_df)\n",
        "valid_df = remove_invalid_annots(valid_df)\n",
        "test_df  = remove_invalid_annots(test_df)"
      ],
      "metadata": {
        "id": "Uho3D0L-GIME"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "train_df.head()\n",
        "valid_df.head()\n",
        "test_df.head()\n",
        "'''"
      ],
      "metadata": {
        "id": "1ya2D2hKFsYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Paths where to save the generated dataframes\n",
        "TRAIN_CSV = \"/content/train_data.csv\"\n",
        "VALID_CSV = \"/content/valid_data.csv\"\n",
        "TEST_CSV  = \"/content/test_data.csv\"\n",
        "\n",
        "# #Save the dataframes to memory\n",
        "train_df.to_csv(TRAIN_CSV, index=False)\n",
        "valid_df.to_csv(VALID_CSV, index=False)\n",
        "test_df.to_csv(TEST_CSV, index=False)"
      ],
      "metadata": {
        "id": "8aVqJkz_FgCm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(TRAIN_CSV)\n",
        "valid_df = pd.read_csv(VALID_CSV)\n",
        "test_df  = pd.read_csv(TEST_CSV)"
      ],
      "metadata": {
        "id": "RLzX7XMuGjBO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.pascal import generate_pascal_category_names\n",
        "\n",
        "LABEL_MAP = generate_pascal_category_names(train_df)\n",
        "LABEL_MAP"
      ],
      "metadata": {
        "id": "sHrxfvqBGjXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import visualize_boxes_and_labels_on_image_array as viz_bbs\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def grab_bbs_(dataframe, index:int):\n",
        "    \"\"\"\n",
        "    Takes in a Pandas DataFrame and a index number\n",
        "    Returns filename of the image and all the bounding boxes and class_labels\n",
        "    corresponding the image that is at the given index\n",
        "\n",
        "    Params\n",
        "    ------\n",
        "        dataframe : a pandas dataframe object\n",
        "        index (int) : a integer corresponding to a index in the pandas dataframe\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        fname (str) : path to the selected image.\n",
        "        bbbs (list) : a list containing the bounding box annotations for the `fname`.\n",
        "        cls (list) : a list containing the integer class labels for the box annotations.  \n",
        "    \"\"\"\n",
        "    assert index <= len(dataframe), f\"Invalid index for dataframe with len: {len(dataframe)}\"\n",
        "    fname = dataframe.filename[index]\n",
        "    locs  = dataframe.loc[dataframe.filename == fname]\n",
        "    bbs   = locs[[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values\n",
        "    cls   = locs[\"labels\"].values\n",
        "    return fname, bbs, cls\n",
        "\n",
        "def load_image_from_data(dataframe, index):\n",
        "    \"\"\"\n",
        "    Loads in a image from the given dataframe at given index\n",
        "    Returns a PIL image object contraining all the bounding boxes over\n",
        "    the image\n",
        "    \"\"\"\n",
        "    image, boxes, clas = grab_bbs_(dataframe, index)\n",
        "    #load and normalize the image\n",
        "    image = Image.open(image)\n",
        "    image = np.array(image) / 255.\n",
        "    image = viz_bbs(image, boxes, scores=None, classes=clas, label_map=LABEL_MAP)\n",
        "    return image"
      ],
      "metadata": {
        "id": "3Y8Cs1mdGp4r"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "image = load_image_from_data(train_df, index=10)\n",
        "image\n",
        "'''\n",
        "'''\n",
        "image = load_image_from_data(valid_df, index=27)\n",
        "image\n",
        "'''\n",
        "'''\n",
        "image = load_image_from_data(test_df, index=2)\n",
        "image\n",
        "'''"
      ],
      "metadata": {
        "id": "wCqTbTiPGp7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_TRAIN_EPOCHS = 100\n",
        "from omegaconf import OmegaConf\n",
        "\n",
        "#load in the hparams.ymal file using Omegaconf\n",
        "hparams = OmegaConf.load(\"/content/pytorch_retinanet/hparams.yaml\")\n",
        "\n",
        "# ========================================================================= #\n",
        "# MODIFICATION OF THE CONFIG FILE TO FIX PATHS AND DATSET-ARGUEMENTS :\n",
        "# ========================================================================= #\n",
        "hparams.dataset.kind        = \"csv\"\n",
        "hparams.dataset.trn_paths   = TRAIN_CSV\n",
        "hparams.dataset.valid_paths = VALID_CSV\n",
        "hparams.dataset.test_paths  = TEST_CSV\n",
        "\n",
        "hparams.dataloader.train_bs = 1\n",
        "hparams.dataloader.valid_bs = 16\n",
        "hparams.dataloader.test_bs  = 16\n",
        "\n",
        "hparams.model.num_classes   = len(LABEL_MAP) - 1 \n",
        "hparams.model.backbone_kind = \"resnet34\"\n",
        "hparams.model.min_size      = 800\n",
        "hparams.model.max_size      = 1333\n",
        "hparams.model.pretrained    = True #loads in imagenet-backbone weights\n",
        "\n",
        "#transforms for the train_dataset\n",
        "hparams.transforms  =  [\n",
        "    {\"class_name\": \"albumentations.HorizontalFlip\", \"params\": {\"p\": 0.5} },\n",
        "    {\"class_name\": \"albumentations.ShiftScaleRotate\", \"params\": {\"p\": 0.5} },\n",
        "    {\"class_name\": \"albumentations.RandomBrightnessContrast\", \"params\": {\"p\": 0.5} },\n",
        "]\n",
        "\n",
        "#optimizer\n",
        "hparams.optimizer = {\n",
        "    \"class_name\": \"torch.optim.SGD\", \n",
        "    \"params\"    : {\"lr\": 0.001, \"weight_decay\": 0.0005, \"momentum\":0.9},\n",
        "    }\n",
        "\n",
        "#scheduler\n",
        "hparams.scheduler = {\n",
        "    \"class_name\" : \"torch.optim.lr_scheduler.CosineAnnealingLR\", \n",
        "    \"params\"     : {\"T_max\": NUM_TRAIN_EPOCHS}, \n",
        "    \"monitor\"    : None, \n",
        "    \"interval\"   : \"epoch\", \n",
        "    \"frequency\"  : 1\n",
        "    }\n",
        "\n",
        "print(OmegaConf.to_yaml(hparams))"
      ],
      "metadata": {
        "id": "iWYeR8dTG4dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor, EarlyStopping\n",
        "\n",
        "from model import RetinaNetModel\n",
        "\n",
        "# seed so that results are reproducible\n",
        "pl.seed_everything(123)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E514kDrHG4mS",
        "outputId": "3f6b7f2f-2caa-4078-95a3-45c39dee13c8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "123"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================ #\n",
        "# INSTANTIATE LIGHTNING-TRAINER with CALLBACKS :\n",
        "# ============================================================ #\n",
        "# NOTE: \n",
        "# For a list of whole trainer specific arguments see : \n",
        "# https://pytorch-lightning.readthedocs.io/en/latest/trainer.html\n",
        "\n",
        "lr_logger  = LearningRateMonitor(logging_interval=\"step\")\n",
        "\n",
        "#instantiate LightningTrainer\n",
        "trainer    = Trainer(precision=16, gpus=1, callbacks=[lr_logger], max_epochs=NUM_TRAIN_EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-SSPj5jG4os",
        "outputId": "68fc953f-3bbe-4d5f-c435-b3a55a029291"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Using native 16bit precision.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate lightning-module\n",
        "litModel = RetinaNetModel(conf=hparams)"
      ],
      "metadata": {
        "id": "9hO1cOdDa2GE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(litModel)"
      ],
      "metadata": {
        "id": "hceOaDHCb3VG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(litModel)"
      ],
      "metadata": {
        "id": "7F_sFmfla2Mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "PATH = f\"/content/trained_weights.pth\"\n",
        "torch.save(litModel.net.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "46Z_Z0n7bAyc"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logger = logging.getLogger(\"lightning\")"
      ],
      "metadata": {
        "id": "xsy5ImU0bJGM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from retinanet import Retinanet\n",
        "\n",
        "#load saved model state dict\n",
        "state_dict = torch.load(PATH)\n",
        "#model arguments same as the arguments used to train the model\n",
        "model_args = hparams.model\n",
        "#load pytorch model without the lightning-module\n",
        "#using args and state dict\n",
        "MODEL      = Retinanet(**model_args, logger=logger)\n",
        "MODEL.load_state_dict(state_dict)\n",
        "MODEL.eval()\n",
        "MODEL.to(\"cuda:0\");"
      ],
      "metadata": {
        "id": "ybQwtOUabKNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "@torch.no_grad()\n",
        "def get_preds(path, threshold=0.6,):\n",
        "    \"\"\"\n",
        "    Generates predictions on the given image from the given path.\n",
        "\n",
        "    Params\n",
        "    ------\n",
        "        image_path (str) : Path to the input Image\n",
        "        threshold (float): Score threshold to filter predictions\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        A Dictionary contatining the predictions from generated from the model on \n",
        "        the given image. \n",
        "        Keys of the dictionary: \n",
        "          - \"boxes\" : bounding-box co-ordinates\n",
        "          - \"labels\": class labels for the bounding box co-ordinates.\n",
        "          - \"scores\": scores for the bounding box co-ordinates.\n",
        "    \"\"\"\n",
        "    image = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    INFER_TRANSFORMS = A.Compose([\n",
        "        A.ToFloat(max_value=255.0, always_apply=True),\n",
        "        ToTensorV2(always_apply=True)\n",
        "        ])\n",
        "    \n",
        "    TENSOR_IMAGE = INFER_TRANSFORMS(image=image)[\"image\"].to(\"cuda:0\")\n",
        "    PREDICTIONS  = MODEL.predict([TENSOR_IMAGE])\n",
        "    return PREDICTIONS[0]\n",
        "\n",
        "def detect(image_path, threshold=0.6):\n",
        "    \"\"\"\n",
        "    Generate detections on the image that is present in \n",
        "    the given image path\n",
        "\n",
        "    Params\n",
        "    ------\n",
        "        image_path `(str)` : Path to the input Image\n",
        "        threshold `(float)`: Score threshold to filter predictions\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "        boxes  `(np.array)`: filtered absolute bounding box co-ordinates.\n",
        "        labels `(np.array)`: class labels for the bounding box co-ordinates.\n",
        "        scores `(np.array)`: scores for the bounding box co-ordinates.\n",
        "    \"\"\"\n",
        "    # Generate predictions for the given image\n",
        "    preds = get_preds(image_path, threshold,)\n",
        "    # print(preds)\n",
        "    # Filter predictions\n",
        "    boxes, labels, scores = preds[\"boxes\"], preds[\"labels\"], preds[\"scores\"]\n",
        "    mask   = scores > threshold\n",
        "    boxes  = boxes[mask]\n",
        "    labels = labels[mask]\n",
        "    scores = scores[mask]\n",
        "    return boxes.cpu().numpy(), labels.cpu().numpy(), scores.cpu().numpy()\n",
        "\n",
        "def draw_on_image(image_path, boxes, scores, classes, label_map=LABEL_MAP):\n",
        "    \"\"\"\n",
        "    Draw bounding box over the image at image path, with the scores and classes\n",
        "    Returns a PIL image object.\n",
        "    \n",
        "    Params\n",
        "    ------ \n",
        "        image_path `(str)`   : Path to the input Image\n",
        "        boxes `(List[N,4])`  : absolute bouding box co-ordiates in the form `[xmin,ymin,xmax,ymax]`.\n",
        "        scores `(List[N])`   : List containing the scores for each of the bounding box.\n",
        "        classes `(`List[N])` : List containing the class_labels for each of the bounding box.\n",
        "        label_map `(List)`   : List of the labels\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        A PIL Image object\n",
        "    \"\"\"\n",
        "    image = Image.open(image_path)\n",
        "    image = np.array(image) / 255.\n",
        "    image = viz_bbs(image, boxes, scores=scores, classes=classes, label_map=LABEL_MAP)\n",
        "    return image"
      ],
      "metadata": {
        "id": "acxxAHmZbKP8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.random.randint(len(test_df))\n",
        "\n",
        "#Path to the image\n",
        "image_path = test_df.filename[idx]\n",
        "#generate predictions for the image\n",
        "boxes, labels, scores = detect(image_path, threshold=0.60)\n",
        "\n",
        "pred_image = draw_on_image(image_path, boxes, scores, labels)\n",
        "\n",
        "real_image = load_image_from_data(test_df, index=idx)\n",
        "\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(ncols=2, nrows=1, figsize=(20,7))\n",
        "\n",
        "ax1.imshow(real_image)\n",
        "ax1.set_title(\"Original\")\n",
        "ax1.axis(\"off\")\n",
        "\n",
        "ax2.imshow(pred_image)\n",
        "ax2.set_title(\"Predictions\")\n",
        "ax2.axis(\"off\");"
      ],
      "metadata": {
        "id": "ljZWF298bUSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.random.randint(len(test_df))\n",
        "\n",
        "#Path to the image\n",
        "image_path = test_df.filename[idx]\n",
        "#generate predictions for the image\n",
        "boxes, labels, scores = detect(image_path, threshold=0.60)\n",
        "\n",
        "pred_image = draw_on_image(image_path, boxes, scores, labels)\n",
        "\n",
        "real_image = load_image_from_data(test_df, index=idx)\n",
        "\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(ncols=2, nrows=1, figsize=(20,7))\n",
        "\n",
        "ax1.imshow(real_image)\n",
        "ax1.set_title(\"Original\")\n",
        "ax1.axis(\"off\")\n",
        "\n",
        "ax2.imshow(pred_image)\n",
        "ax2.set_title(\"Predictions\")\n",
        "ax2.axis(\"off\");"
      ],
      "metadata": {
        "id": "Ec7rU8qUbb0c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}